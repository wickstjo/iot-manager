{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import base64\n",
    "import hashlib\n",
    "import wget\n",
    "import zipfile\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGGING OUTLINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg):\n",
    "    print('[LAUNCHER] ' + msg.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD YAML FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(path):\n",
    "    with open(path, mode='r') as file:\n",
    "        return yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD & SAVE JSON FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path) as json_file:\n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, path):\n",
    "    with open(path, 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODE & DECODE FOR BASE64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data):\n",
    "    \n",
    "    # STRINGIFY & CONVERT TO BYTES\n",
    "    stringified = json.dumps(data)\n",
    "    to_bytes = str.encode(stringified)\n",
    "    \n",
    "    # ENCODE\n",
    "    encoded = base64.b64encode(to_bytes)\n",
    "    \n",
    "    # RETURN AS STRING\n",
    "    return encoded.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(compressed):\n",
    "    \n",
    "    # ATTEMPT TO DECODE & PARSE AS JSON\n",
    "    try:\n",
    "        to_bytes = base64.b64decode(compressed)\n",
    "        return json.loads(to_bytes)\n",
    "    \n",
    "    # OTHERWISE, RETURN EMPTY OBJECT\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILTER ZEROS FROM BACKLOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_backlog(data):\n",
    "    \n",
    "    # FILTER ZEROS\n",
    "    filtered = filter(lambda x: x != '0x0000000000000000000000000000000000000000', data)\n",
    "    \n",
    "    # CONVERT TO LIST & RETURN\n",
    "    return list(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARE DISCOVERY PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_discovery(data, base):\n",
    "    \n",
    "    # RESULT CONTAINER\n",
    "    result = []\n",
    "    \n",
    "    # LOOP THROUGH DATA KEYS\n",
    "    for key in data:\n",
    "        \n",
    "        # IF THE KEY EXISTS IN THE BASE DICT\n",
    "        if key in base:\n",
    "            \n",
    "            # IF THE VALUE IS SAME IN BOTH DATASET\n",
    "            if data[key] == base[key]:\n",
    "                result.append(True)\n",
    "                \n",
    "            # OTHERWISE, DEFAULT TO FALSE\n",
    "            else:\n",
    "                result.append(False)\n",
    "                \n",
    "        # OTHERWISE, DEFAULT TO FALSE\n",
    "        else:\n",
    "            result.append(False)\n",
    "            \n",
    "    # FINALLY RETURN RESULT\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKSUM STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_checksum(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return hashlib.sha224(file.read()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_checksums(prefix):\n",
    "    \n",
    "    # LOAD CHECKSUMS & EXTRACT FILENAMES\n",
    "    checksums = load_json(prefix + 'checksums.json')\n",
    "    files = list(checksums.keys())\n",
    "    \n",
    "    # RESULT CONTAINER\n",
    "    results = []\n",
    "    \n",
    "    # LOOP THROUGH FILES\n",
    "    for file in files:\n",
    "        \n",
    "        # GENERATE CHECKSUM FOR FILE\n",
    "        checksum = generate_checksum(prefix + file)\n",
    "        \n",
    "        # VERIFY & PUSH RESULT\n",
    "        results.append(checksum == checksums[file])\n",
    "    \n",
    "    # IF ALL FILES PASS, RETURN TRUE\n",
    "    if (results.count(False) == 0):\n",
    "        return True\n",
    "    \n",
    "    # OTHERWISE, RETURN FALSE\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOWNLOAD FILE -- RETURN FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url):\n",
    "    return wget.download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZIP / UNZIP DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(path, target):\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zip(files, prefix, path):\n",
    "    with zipfile.ZipFile(prefix + path, 'w') as zipF:\n",
    "        for file in files:\n",
    "            zipF.write(prefix + file, compress_type=zipfile.ZIP_DEFLATED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(name):\n",
    "\n",
    "    # CHECK IF THE DIR EXISTS\n",
    "    exists = os.path.exists(name)\n",
    "    \n",
    "    # IF IT DOES, DELETE IT\n",
    "    if exists:\n",
    "        shutil.rmtree(name)\n",
    "        \n",
    "    # CREATE A FRESH DIR\n",
    "    os.mkdir(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECRYPT PRIVATE KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_key(path, password, web3):\n",
    "    with open(path) as keyfile:\n",
    "        encrypted_key = keyfile.read()\n",
    "        private_key = web3.eth.account.decrypt(encrypted_key, password)\n",
    "\n",
    "        return web3.toHex(private_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
